{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages and libraries that will be needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "#The package by itself comes with a single module and an estimator.To install the module execute:pip install category_encoders\n",
    "import category_encoders as ce\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV as LRCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  delivery_no  delivery_time  blood_pressure  heart_problem\n",
      "0   21            0              0               0              0\n"
     ]
    }
   ],
   "source": [
    "#read data\n",
    "Dataset = pd.read_csv(\"caesarian.csv\")\n",
    "Pred = pd.read_csv('caesarianPred.csv')\n",
    "print(Pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To replace the missing data with the recommended \n",
    "inputs we need to know if variable type is compatible \n",
    "with this imputation, hence check variable type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0         int64\n",
      "age               object\n",
      "delivery_no       object\n",
      "delivery_time      int64\n",
      "blood_pressure     int64\n",
      "heart_problem      int64\n",
      "caesarian          int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Dataset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The columns with missing values are of data type \"Object\" and it is recommended to replace missing values with mean and mode respectively, to make it easy, it is advisable to replace missing values with zeros since there are no zeros in these columns and convert the columns to \"ints\" to able to use the mean and mode function in pandas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing missing values (-) with zeros(0)\n",
    "Dataset['delivery_no'] = Dataset['delivery_no'].str.replace('-', '0')\n",
    "Dataset['age'] = Dataset['age'].str.replace('-', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting data type objects to int64\n",
    "Dataset['age'] = Dataset['age'].astype('int64')\n",
    "Dataset['delivery_no'] = Dataset['delivery_no'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now, since the column, age is of the data type int64 it is easy to replace all zeros, which in actual fact are missing values with the mean value of the column, likewise the delivery_no column, zeros with the mode of the column*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age = round(Dataset['age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['age']=Dataset.age.mask(Dataset.age == 0,mean_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_delivery_no = round(Dataset['delivery_no'].mode())\n",
    "Dataset['delivery_no']=Dataset.delivery_no.mask(Dataset.delivery_no == 0, mode_delivery_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>age</th>\n",
       "      <th>delivery_no</th>\n",
       "      <th>delivery_time</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>heart_problem</th>\n",
       "      <th>caesarian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit   age  delivery_no  delivery_time  blood_pressure  heart_problem  \\\n",
       "0   0.0  22.0          1.0            0.0             2.0            0.0   \n",
       "1   1.0  26.0          2.0            0.0             1.0            0.0   \n",
       "2   2.0  26.0          2.0            1.0             1.0            0.0   \n",
       "3   3.0  28.0          1.0            0.0             2.0            0.0   \n",
       "4   4.0  22.0          2.0            0.0             1.0            0.0   \n",
       "5   5.0  26.0          1.0            1.0             0.0            0.0   \n",
       "6   6.0  27.0          2.0            0.0             1.0            0.0   \n",
       "7   7.0  26.0          1.0            0.0             1.0            0.0   \n",
       "8   8.0  26.0          2.0            0.0             1.0            0.0   \n",
       "9   9.0  27.0          1.0            1.0             1.0            0.0   \n",
       "\n",
       "   caesarian  \n",
       "0        0.0  \n",
       "1        1.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        1.0  \n",
       "5        0.0  \n",
       "6        0.0  \n",
       "7        1.0  \n",
       "8        0.0  \n",
       "9        1.0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For whatever reason the above imputation seems to replace zeros with NaN, hence apply SimpleImputer to replace the NaN that get generated \n",
    "imp = SimpleImputer(missing_values= np.NaN, strategy='most_frequent')\n",
    "\n",
    "#the fit and transform are a numpy attribute so use pandas.DataFrame to take it back to DataFrame \n",
    "imp.fit(Dataset)\n",
    "Dataset = pd.DataFrame(imp.transform(Dataset))\n",
    "\n",
    "#Replace the original headings with indeces numpy creates with DataFrame.columns\n",
    "Dataset.columns = ['unit', 'age', 'delivery_no', 'delivery_time', 'blood_pressure', 'heart_problem', 'caesarian']\n",
    "Dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dividing the DataFrame to Response and Explanatory Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   caesarian\n",
      "0        0.0\n",
      "1        1.0\n",
      "2        0.0\n",
      "3        0.0\n",
      "4        1.0\n",
      "    age  delivery_no  delivery_time  blood_pressure  heart_problem\n",
      "0  22.0          1.0            0.0             2.0            0.0\n",
      "1  26.0          2.0            0.0             1.0            0.0\n",
      "2  26.0          2.0            1.0             1.0            0.0\n",
      "3  28.0          1.0            0.0             2.0            0.0\n",
      "4  22.0          2.0            0.0             1.0            0.0\n"
     ]
    }
   ],
   "source": [
    "#Dependant variable selection\n",
    "Dependant = Dataset.loc[:,['caesarian']]\n",
    "\n",
    "#Independent variable selection\n",
    "Independent = Dataset.loc[:,['age', 'delivery_no', 'delivery_time', 'blood_pressure', 'heart_problem']]\n",
    "print(Dependant.head(5))\n",
    "print(Independent.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENCODING CATEGORICAL FEATURES**\n",
    "\n",
    "*Encoding the categorical variables using \"category_encoders\", it follows the same API as sklearnâ€™s preprocessors. They have some added conveniences, such as the ability to easily add an encoder to a pipeline. Additionally, the encoder returns a pandas DataFrame if a DataFrame is passed in. I am using this because it seems to follow the usual practice of other statistical software* \n",
    "[category_encoders](https://pypi.org/project/category_encoders/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delivery_time_0</th>\n",
       "      <th>blood_pressure_0</th>\n",
       "      <th>heart_problem_0</th>\n",
       "      <th>age</th>\n",
       "      <th>delivery_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   delivery_time_0  blood_pressure_0  heart_problem_0  age  delivery_no\n",
       "0                1                 1                1   21            0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate an encoder - here we use Binary()\n",
    "encod_val = ce.BinaryEncoder(cols = ['delivery_time', 'blood_pressure', 'heart_problem'])\n",
    "\n",
    "# fit and transform\n",
    "Independent = encod_val.fit_transform(Independent)\n",
    "Pred = encod_val.fit_transform(Pred)\n",
    "Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delivery_time_0</th>\n",
       "      <th>blood_pressure_0</th>\n",
       "      <th>heart_problem_0</th>\n",
       "      <th>age</th>\n",
       "      <th>delivery_no</th>\n",
       "      <th>blood_pressure_1</th>\n",
       "      <th>delivery_time_2</th>\n",
       "      <th>heart_problem_1</th>\n",
       "      <th>blood_pressure_2</th>\n",
       "      <th>delivery_time_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   delivery_time_0  blood_pressure_0  heart_problem_0  age  delivery_no  \\\n",
       "0                1                 1                1   21            0   \n",
       "\n",
       "   blood_pressure_1  delivery_time_2  heart_problem_1  blood_pressure_2  \\\n",
       "0               0.0              0.0              0.0               0.0   \n",
       "\n",
       "   delivery_time_1  \n",
       "0              0.0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training set and Predicted set shape and dimension manipulations to make them equalin size\n",
    "Diff_shape_p = set(Independent) - set(Pred)\n",
    "Diff_shape_p = pd.DataFrame(data = np.zeros((Pred.shape[0], len(Diff_shape_p))), columns = list(Diff_shape_p))\n",
    "Pred = Pred.join(Diff_shape_p)\n",
    "Pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardization**\n",
    "\n",
    "*Standardize the new features by removing the mean and scaling to unit variance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   delivery_time_0  delivery_time_1  delivery_time_2  blood_pressure_0  \\\n",
      "0              0.0        -0.859727         0.519462               0.0   \n",
      "\n",
      "   blood_pressure_1  blood_pressure_2  heart_problem_0  heart_problem_1  \\\n",
      "0         -1.732051               1.0        -0.774597         0.774597   \n",
      "\n",
      "        age  delivery_no  \n",
      "0 -1.186046    -0.697097  \n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CHERPENS\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\CHERPENS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\CHERPENS\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\CHERPENS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "standardize = preprocessing.StandardScaler().fit(Independent)\n",
    "Independent = pd.DataFrame(standardize.transform(Independent))\n",
    "Independent.columns = ['delivery_time_0', 'delivery_time_1', 'delivery_time_2',\n",
    "                       'blood_pressure_0', 'blood_pressure_1', 'blood_pressure_2',\n",
    "                       'heart_problem_0', 'heart_problem_1','age', 'delivery_no']\n",
    "print(Independent.head(1))\n",
    "\n",
    "#standardization for predicted dataset\n",
    "Pred_standardize = preprocessing.StandardScaler().fit(Pred)\n",
    "Pred = Pred_standardize.transform(Pred)\n",
    "#Pred = pd.DataFrame(standardize.transform(Pred))\n",
    "#Pred.columns = ['delivery_time_0', 'delivery_time_1', 'delivery_time_2',\n",
    "                       #'blood_pressure_0', 'blood_pressure_1', 'blood_pressure_2',\n",
    "                       #'heart_problem_0', 'heart_problem_1','age', 'delivery_no']\n",
    "print(Pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Training and  Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data into Training and Testing Set 70/30 respectively \n",
    "Indep_train, Indep_test, Dep_train, Dep_test = train_test_split(Independent, Dependant, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - L2 with 100 regularization coefficients and 3-fold cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/alpha =  [0.00599484]\n",
      "coef =  [[ 0.         -0.03491522  0.01640852  0.         -0.01972001  0.05454202\n",
      "   0.05363667 -0.05363667  0.0112653   0.01791942]]\n",
      "accuracy =  0.65\n",
      "Predicted outcome using Accuracy Scoring function: [1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CHERPENS\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression and cross validation\n",
    "Logit_RegCV_L2 = LRCV(Cs=10, cv=10, penalty='l2', random_state=0, multi_class='multinomial', solver='lbfgs', max_iter=1000, n_jobs=-1)\n",
    "Logit_RegCV_L2.fit(Independent, Dependant)\n",
    "print('1/alpha = ', Logit_RegCV_L2.C_) \n",
    "print('coef = ', Logit_RegCV_L2.coef_)\n",
    "print('accuracy = ', Logit_RegCV_L2.score(Independent, Dependant))\n",
    "print('Predicted outcome using Accuracy Scoring function:', Logit_RegCV_L2.predict(Pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a model where the regularization coefficient is determined using the\n",
    "accuracy as the scoring function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy without normalization:  52\n",
      "accuracy with normalization:  0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CHERPENS\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/alpha =  [0.00599484]\n",
      "coef =  [[ 0.         -0.03491522  0.01640852  0.         -0.01972001  0.05454202\n",
      "   0.05363667 -0.05363667  0.0112653   0.01791942]]\n",
      "accuracy =  0.65\n",
      "average predicted accuracy 0.6118055555555554\n",
      "Expected value for thie model -76.24999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CHERPENS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1926: ChangedBehaviorWarning: The long-standing behavior to use the accuracy score has changed. The scoring parameter is now used. This warning will disappear in version 0.22.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    }
   ],
   "source": [
    "#generate the predicted Y based on the model\n",
    "y_pred = Logit_RegCV_L2.predict(Independent)\n",
    "\n",
    "#Creating Accuracy Scoring Function\n",
    "accuracy = accuracy_score(Dependant, y_pred)\n",
    "N_accuracy = accuracy_score(Dependant, y_pred, normalize = False)\n",
    "print('accuracy without normalization: ', N_accuracy)\n",
    "print('accuracy with normalization: ', accuracy)\n",
    "\n",
    "#Traning Logistic Regression Model with Cross Validation using Accuracy Scoring Function\n",
    "Logit_RegCV_L2_ac = LRCV(Cs=10, cv=10, penalty='l2', \n",
    "                                      scoring= 'accuracy', random_state=0, \n",
    "                                      multi_class='multinomial', solver='lbfgs', \n",
    "                                      max_iter=1000, n_jobs=-1)\n",
    "\n",
    "#fitting the just trained model\n",
    "Logit_RegCV_L2_ac.fit(Independent, Dependant)\n",
    "Acc_Scores = Logit_RegCV_L2_ac.scores_\n",
    "print('1/alpha = ', Logit_RegCV_L2_ac.C_) \n",
    "print('coef = ', Logit_RegCV_L2_ac.coef_)\n",
    "print('accuracy = ', Logit_RegCV_L2_ac.score(Independent,Dependant))\n",
    "print('average predicted accuracy', np.array(list(Acc_Scores.values())).mean())\n",
    "print('Expected value for thie model', EV_score(Logit_RegCV_L2_ac, Independent,Dependant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train another model where the regularization coefficient is determined using the expected value as the scoring function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average predicted Expected Value -91.91865079365074\n",
      "coef =  [[ 0.         -0.00071508  0.00043007  0.         -0.0005709   0.00119289\n",
      "   0.00138122 -0.00138122  0.00034953  0.00046433]]\n",
      "Expected value for thie model -76.25000000000001\n",
      "Predicted outcome using Expected value Scoring function: [1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CHERPENS\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Creating Expected value scoring function\n",
    "def EV_score(estimator, X, Y):\n",
    "    EV_y_pred = estimator.predict(X)\n",
    "    EV_Confusion_Matrix = confusion_matrix(EV_y_pred, Y)\n",
    "    Prob_TN, Prob_FP, Prob_FN, Prob_TP = EV_Confusion_Matrix.ravel()/np.sum(EV_Confusion_Matrix)\n",
    "    Expected_Value = 200*Prob_TP - 400*Prob_TN - 450*Prob_FN\n",
    "    return Expected_Value\n",
    "\n",
    "\n",
    "#Traning Logistic Regression Model with Cross Validation Using Expected Value Scoring Function\n",
    "Logit_RegCV_L2_EV = LRCV(Cs=10, cv=10, penalty='l2', \n",
    "                                      scoring= EV_score, random_state=0, \n",
    "                                      multi_class='multinomial', solver='lbfgs', \n",
    "                                      max_iter=1000, n_jobs=-1)\n",
    "\n",
    "#fitting the just trained model\n",
    "Logit_RegCV_L2_EV.fit(Independent, Dependant)\n",
    "EV_scores = Logit_RegCV_L2_EV.scores_\n",
    "print('average predicted Expected Value', np.array(list(EV_scores.values())).mean())\n",
    "print('coef = ', Logit_RegCV_L2_EV.coef_)\n",
    "#print('accuracy = ', Logit_RegCV_L2_EV.score(Independent,Dependant))\n",
    "print('Expected value for thie model', EV_score(Logit_RegCV_L2_EV, Independent,Dependant))\n",
    "print('Predicted outcome using Expected value Scoring function:', Logit_RegCV_L2.predict(Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
